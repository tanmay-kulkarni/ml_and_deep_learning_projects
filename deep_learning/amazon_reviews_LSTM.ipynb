{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lAJYWny4vAis"
   },
   "source": [
    "<h1 align=\"center\">Classifying Amazon Food Reviews using LSTMs </h1>\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The Amazon Food Reviews is a dataset published [here](https://www.kaggle.com/snap/amazon-fine-food-reviews) on Kaggle of nearly 500K user reviews collected on the site for more than ten years upto 2012. The original dataset has a rating of 1 to 5 for each of the products given by the users along with their text reviews. Based on this rating, the objective of this study is to predict  whether a review is positive or negative.\n",
    "\n",
    "I've cleaned the data already and saved it on disk. The two important columns in it which we'll use are `cleaned_text` and `Score`. The column Score is our Target variable with values 0 or 1 and it  indicates whether the review is positive or negative. The value 0 bein negative and 1 being positive.\n",
    "\n",
    "Let's start by importing the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EbC40XbN1tyg"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0ssNTgSx6se"
   },
   "source": [
    "### Mount the Google Drive\n",
    "\n",
    "The cleaned dataframe is stored on my Google Drive and I'm using Colaboratory because it has access to a GPU environment. The following block of code attaches the drive to Google Colaboratory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "mFZGz_FP1c5f",
    "outputId": "ad1aeec3-460a-4459-9de5-c5345b36e6c6"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOcmvxCpyYhL"
   },
   "source": [
    "## Load the reviews from disk\n",
    "\n",
    "The reviews are stored in a `.sqlite`  file. Load them in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3TbYQwP1u0q"
   },
   "outputs": [],
   "source": [
    "# load sqlite database\n",
    "con = sqlite3.connect('/gdrive/My Drive/amazon/reviews_cleaned_final.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "colab_type": "code",
    "id": "B9Lip2lo2Koq",
    "outputId": "c69c9c53-51f4-4b95-f9aa-4f61bba40a5b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>b'bought sever vital can dog food product foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>b'product arriv label jumbo salt peanut peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>b'confect around centuri light pillowi citru g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>b'look secret ingredi robitussin believ found ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>b'great taffi great price wide assort yummi ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId          UserId                      ProfileName  \\\n",
       "index                                                                    \n",
       "0       1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1       2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2       3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3       4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4       5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "       HelpfulnessNumerator  HelpfulnessDenominator     Score        Time  \\\n",
       "index                                                                       \n",
       "0                         1                       1  positive  1303862400   \n",
       "1                         0                       0  negative  1346976000   \n",
       "2                         1                       1  positive  1219017600   \n",
       "3                         3                       3  negative  1307923200   \n",
       "4                         0                       0  positive  1350777600   \n",
       "\n",
       "                     Summary  \\\n",
       "index                          \n",
       "0      Good Quality Dog Food   \n",
       "1          Not as Advertised   \n",
       "2      \"Delight\" says it all   \n",
       "3             Cough Medicine   \n",
       "4                Great taffy   \n",
       "\n",
       "                                                    Text  \\\n",
       "index                                                      \n",
       "0      I have bought several of the Vitality canned d...   \n",
       "1      Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2      This is a confection that has been around a fe...   \n",
       "3      If you are looking for the secret ingredient i...   \n",
       "4      Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                            cleaned_text  \n",
       "index                                                     \n",
       "0      b'bought sever vital can dog food product foun...  \n",
       "1      b'product arriv label jumbo salt peanut peanut...  \n",
       "2      b'confect around centuri light pillowi citru g...  \n",
       "3      b'look secret ingredi robitussin believ found ...  \n",
       "4      b'great taffi great price wide assort yummi ta...  "
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conn = sqlite3.connect('/gdrive/My Drive/amazon/reviews_cleaned_final.sqlite')\n",
    "df = pd.read_sql('select * from Reviews;', con, index_col='index')\n",
    "con.close()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oR5-_mqRysMg"
   },
   "source": [
    "Only keep the `cleaned_text` and `Score` columns because these will be used for training the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3NNf4oi2p5r"
   },
   "outputs": [],
   "source": [
    "df = df[['cleaned_text', 'Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "colab_type": "code",
    "id": "1L_bM2uO29gE",
    "outputId": "e901ad31-d1f5-42ae-dc58-a26493b0cfad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 364171 entries, 0 to 525813\n",
      "Data columns (total 2 columns):\n",
      "cleaned_text    364171 non-null object\n",
      "Score           364171 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ehkAZk2Py8vH"
   },
   "source": [
    "## Generate frequency counts of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "W3nfwX1P2-pN",
    "outputId": "3133c83f-b34e-4f93-b7cf-312885c07c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "counter = Counter()\n",
    "\n",
    "c = 0\n",
    "\n",
    "for review in df.cleaned_text:\n",
    "    for word in review.decode('utf-8').split():\n",
    "        counter[word] += 1\n",
    "    print(c, end='\\r')\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80A9wd-X54gT"
   },
   "source": [
    "Create a dictionary mapping from word to its frequency in the entire review corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcft2T-Y4mGN"
   },
   "outputs": [],
   "source": [
    "word_to_freq_DICT_5k = dict(counter.most_common(5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ssjrq34X5_IM"
   },
   "source": [
    "Reverse the above mapping and store it in another variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "But6ynw764YL"
   },
   "outputs": [],
   "source": [
    "freq_to_word_DICT_5k = {v:k for k, v in word_to_freq_DICT_5k.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OBkWQANX6I0Y"
   },
   "source": [
    "Now, generate mappings between a word and its index and vice versa. e.g. 'abc' : 4 will mean 'abc' is the 4th most frequent word encountered in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWDKsj26BZiA"
   },
   "outputs": [],
   "source": [
    "word_to_index_lookup = dict(zip(freq_to_word_DICT_5k.values(), range(1,5001)))\n",
    "index_to_word_lookup = {v:k for k,v in word_to_index_lookup.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4NuF8JSU6m8n"
   },
   "source": [
    "Create a dummy column in the dataframe. This column will contain the index-vector representation of each review. i.e. each word in a review is replaced by its index from the mapping we defined above. This index is what will be given as input to the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBgAZ75eCBO9"
   },
   "outputs": [],
   "source": [
    "df['freq_vectors'] = df.cleaned_text\n",
    "\n",
    "def text_to_word_frequency(review):\n",
    "    return [word_to_index_lookup[word] if word in word_to_index_lookup.keys() else 0 for word in review.decode('utf-8').split()]\n",
    "\n",
    "df['freq_vectors'] = df.freq_vectors.map(text_to_word_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jC1ql787PJT"
   },
   "source": [
    "Here's what the new index-vectorized reviews look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Lk-QLiFEGIa_",
    "outputId": "cd4a56d1-63fd-4947-e8cc-f6fc89c6def4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 193, 0, 246, 0, 1378, 0, 262, 209, 0, 382, 692, 0, 0, 529, 238, 43, 692, 361, 1224, 522, 3, 171, 44, 396, 57, 0, 1477, 0, 0, 0, 0, 57, 0, 0, 354, 0, 1124, 0]\n"
     ]
    }
   ],
   "source": [
    "print(df['freq_vectors'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CAJwWUJY7kJQ"
   },
   "source": [
    "Map the Score variable from string to an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hln7OyCnHX5J"
   },
   "outputs": [],
   "source": [
    "df.Score = df.Score.map({'positive' : 1, 'negative' : 0 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70u1Haorzx0_"
   },
   "source": [
    "## Train  and Test data\n",
    "\n",
    "Let's divide all the reviews in the ratio 80:20 for Train and Test respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xrMXrncGYKC"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.freq_vectors.values,df.Score.values, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "jVB1w3x8IGlt",
    "outputId": "4830c532-329f-45b1-eda8-805d71e26ae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((291336,), (291336,), (72835,), (72835,))"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape,  X_test.shape,  y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfOrYeB7I1Mp"
   },
   "source": [
    "## Truncate or Pad input sequences\n",
    "\n",
    "In real world data, it is impossible that each review will have the same length. But our neural network requires that the length of input is consistent. To that end, we'll fix the length of each review to 75 words and pad the reviews which are smaller than 75 words by zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "colab_type": "code",
    "id": "tD1za_XDJL4N",
    "outputId": "9afe3aff-189e-4e0f-9c09-2127e71a11bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291336, 75)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0  987  105\n",
      "  378 1269    2  396  317    0   98  121  140   95    6  113  105    0\n",
      "  364  369  105   43 1452  145  378  142   98  780  234    3    9  815\n",
      "    0   85  151  370  495]\n"
     ]
    }
   ],
   "source": [
    "# truncate and/or pad input sequences\n",
    "max_review_length = 75\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwgIZFtUTnHT"
   },
   "source": [
    "Shape of input train and test data after padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "7K37_if4LiM8",
    "outputId": "b3064a7d-f99a-413f-c962-f9b5af8f5e9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((291336, 75), (72835, 75), (291336,), (72835,))"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L01GIwy9KGPv"
   },
   "source": [
    "## Model 1\n",
    "\n",
    "\n",
    "Architecture: \n",
    "\n",
    "**[ 75(E) - 100(L) - 1(Sigmoid Output) ]**\n",
    "\n",
    "\n",
    "where \n",
    "\n",
    "E = Embedding Layer\n",
    "\n",
    "L = LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "a-IF0qOIKGif",
    "outputId": "559e2231-dd65-413a-cff4-1f170b03a86f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 75, 32)            160000    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "top_words = 5000\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n",
    "#Refer: https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mdauAaNVXsMg"
   },
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vz-AIm9dXrv9"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), keras_metrics.recall() ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGws-rxwKK3X"
   },
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "VIaWtEp2KbXb",
    "outputId": "164a1354-cc8b-4181-de09-9c905e7fa6fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 291336 samples, validate on 72835 samples\n",
      "Epoch 1/3\n",
      "291336/291336 [==============================] - 973s 3ms/step - loss: 0.2255 - acc: 0.9097 - precision: 0.9297 - recall: 0.9659 - val_loss: 0.2082 - val_acc: 0.9167 - val_precision: 0.9398 - val_recall: 0.9630\n",
      "Epoch 2/3\n",
      "291336/291336 [==============================] - 985s 3ms/step - loss: 0.1954 - acc: 0.9212 - precision: 0.9394 - recall: 0.9690 - val_loss: 0.1900 - val_acc: 0.9237 - val_precision: 0.9403 - val_recall: 0.9712\n",
      "Epoch 3/3\n",
      "291336/291336 [==============================] - 993s 3ms/step - loss: 0.1819 - acc: 0.9271 - precision: 0.9447 - recall: 0.9703 - val_loss: 0.1859 - val_acc: 0.9258 - val_precision: 0.9440 - val_recall: 0.9696\n",
      "72835/72835 [==============================] - 179s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "#model.fit(X_train, y_train, nb_epoch=10, batch_size=32)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "#print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "yYzK_gCkKcNI",
    "outputId": "af4a2dff-7f8d-487d-def6-532736207ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.58%\n",
      "Precision: 94.40%\n",
      "Recall: 96.96%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"Precision: %.2f%%\" % (scores[2]*100))\n",
    "print(\"Recall: %.2f%%\" % (scores[3]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4JlrFkcZnIB"
   },
   "source": [
    "## Model 2: With Dropout\n",
    "\n",
    "**[ 75(E) - D - 100(L) - D - 1 (sigmoid output)]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "xgG8IWO3Zf9H",
    "outputId": "2d841e9f-296c-4f05-f8f0-cf35aa8426ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 75, 32)            160000    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 75, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4h4FquSnaHyT"
   },
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5YsnRhI_aHoc"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',keras_metrics.precision(), keras_metrics.recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYqtCOIXZ5Kj"
   },
   "source": [
    "## Fit model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "bgtl1iAZZvYG",
    "outputId": "5cdb0960-6546-4c51-b3dc-7a00c26c7ca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 291336 samples, validate on 72835 samples\n",
      "Epoch 1/3\n",
      "291336/291336 [==============================] - 1001s 3ms/step - loss: 0.2276 - acc: 0.9088 - precision: 0.9293 - recall: 0.9653 - val_loss: 0.2062 - val_acc: 0.9172 - val_precision: 0.9328 - val_recall: 0.9718\n",
      "Epoch 2/3\n",
      "291336/291336 [==============================] - 991s 3ms/step - loss: 0.2003 - acc: 0.9198 - precision: 0.9386 - recall: 0.9682 - val_loss: 0.1930 - val_acc: 0.9215 - val_precision: 0.9412 - val_recall: 0.9674\n",
      "Epoch 3/3\n",
      "291336/291336 [==============================] - 986s 3ms/step - loss: 0.1874 - acc: 0.9248 - precision: 0.9426 - recall: 0.9698 - val_loss: 0.1871 - val_acc: 0.9247 - val_precision: 0.9371 - val_recall: 0.9763\n",
      "72835/72835 [==============================] - 176s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "#model.fit(X_train, y_train, nb_epoch=10, batch_size=32)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "#print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "YOPBiwxIZ7k4",
    "outputId": "2fb09111-c26b-4cb9-fd02-b277ce2249c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.47%\n",
      "Precision: 93.71%\n",
      "Recall: 97.63%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"Precision: %.2f%%\" % (scores[2]*100))\n",
    "print(\"Recall: %.2f%%\" % (scores[3]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "EAh-HdvOoH8Q",
    "outputId": "12d60684-f9c2-4905-f00b-b33919d29922"
   },
   "outputs": [],
   "source": [
    "#!pip install keras-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CGTG-_5v7zYS"
   },
   "source": [
    "# Conclusion:\n",
    "\n",
    "* We classifed Amazon Food Reviwes using LSTMs. The two architectures we tried were:\n",
    "    \n",
    "        [ 75(E) - 100(L) - 1(Sigmoid Output) ]\n",
    "        [ 75(E) - D - 100(L) - D - 1 (sigmoid output)]\n",
    " where\n",
    " \n",
    "        E = Embedding Layer\n",
    "        D = Dropout Layer\n",
    "        L = LSTM\n",
    "        \n",
    " Both the models gave similar performance. The accuracy, precision and Recall obtained were:\n",
    "    \n",
    "        - Accuracy: 92.58%\n",
    "        - Precision: 94.40%\n",
    "        - Recall: 96.96%"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "amazon_reviews_LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
